---
title: "CMDA-4654"
subtitle: "Project 1"
author: "Spencer Paragas and Christopher Mascis"
date: "10/31/2021"
output:
  pdf_document:
    highlight: haddock
keep_tex: no
number_sections: no
html_document:
  df_print: paged
geometry: margin = 0.5in
header-includes:
- \usepackage{booktabs}
- \usepackage{longtable}
- \usepackage{array}
- \usepackage{multirow}
- \usepackage{wrapfig}
- \usepackage{float}
- \usepackage{colortbl}
- \usepackage{pdflscape}
- \usepackage{tabu}
- \usepackage{threeparttable}
- \usepackage{threeparttablex}
- \usepackage[normalem]{ulem}
- \usepackage{makecell}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
documentclass: article
urlcolor: blue
---
  
<!-- The above is set to automatically compile to a .pdf file.   -->
<!-- It will only succeed if LaTeX is installed. -->
  
<!-- If you absolutely can't get LaTeX installed and/or working, then you can compile to a .html first,  -->
<!-- by clicking on the arrow button next to knit and selecting Knit to HTML. -->

<!-- You must then print you .html file to a .pdf by using first opening it in a web browser and then printing to a .pdf -->


```{r setup, include=FALSE}
# This is the setup chunk
#  Here you can set global options for the entire document

library(knitr) # I recommend doing this here

# Although you can call functions from a library using the following notation
#  without loading the entire library.
knitr::opts_chunk$set(echo = TRUE, 
                      comment = NA, # Required
                      fig.path = "./figures/",  # Store all figures here in relative path (make the folder first)
                      fig.align = "center",
                      fig.width = 7,
                      fig.height = 7,
                      message = FALSE, # Turn off load messages
                      warning = FALSE # Turn off warnings
                      )

```

\clearpage

```{r include=FALSE}
# You should not echo this chunk.
# include=FALSE does more than echo=FALSE, it actually does: echo=FALSE, results='hide', message=FALSE, warning=FALSE, fig.show='hide'

# You should set your working directory at the very beginning of your R Markdown file
# setwd("~/Dropbox/teaching/FA2020/CMDA_4654/homework/homework1/")

# In linux ~/ is shorthand for /home/username/
# You should type things out properly for your system
# Mac: /Users/username/Documents/CMDA4654/Lectures/Lecture_03/.../
# Windows: C:/Users/username/Documents/etc/Lecture/Lecture_03/.../


```

<!-- ---------------------------------------------------------------------------------------------------- -->
<!-- ---------------- Project Problems start below these lines ----------------------------------------- -->
<!-- ---------------------------------------------------------------------------------------------------- -->


# Problem 1

```{r}
library(dplyr)
library(ggplot2)

#setwd("C:/Users/Spencer/Downloads")
load("ozone.RData")

ggplot(ozone, aes(x = temperature, y = ozone)) + theme_bw() + geom_point()
```


## Part a

Fitting polynomials of different degrees

```{r}
model1 <- lm(ozone ~ poly(radiation,1), data = ozone)
model2 <- lm(ozone ~ poly(radiation,2), data = ozone)
model3 <- lm(ozone ~ poly(radiation,3), data = ozone)
model4 <- lm(ozone ~ poly(radiation,4), data = ozone)
model5 <- lm(ozone ~ poly(radiation,5), data = ozone)
model6 <- lm(ozone ~ poly(radiation,6), data = ozone)

summary(model1)
summary(model2)
summary(model3)
summary(model4)
summary(model5)
summary(model6)
```


The polynomial fit that appears to work the best is the one with degree 3.


## Part b

Writing the function that carries out LOESS regression

```{r}
# This function has the following inputs.
# 
# * x - a numeric input vector
# * y - a numeric response
#
# Note span and degree are shown with their default values.
# * degree should be 1 or 2 only
# * span can be any value in interval (0, 1) non-inclusive.
#
# If show.plot = TRUE then a plot of the final fit is shown

myloess <- function(x, y, span = 0.5, degree = 1, show.plot = TRUE) {
  
  # Getting range of values
  xrange <- diff(range(x))
  
  # Checking span meets requirements and setting width
  if (between(span, 0, 1)) {
    width <- span*xrange
  }
  else {
    stop("Span must be between 0 and 1 non-inclusive")
  }
  
  # Getting total number of points and windows (they'll be the same)
  N_total <- length(x)
  Win_total <- length(x)
  
  # Allocating space for vector of each window's population
  n_points <- vector(mode = "integer", length = length(x))
  
  # Allocating space for vector of fitted values
  yhat <- vector(mode = "numeric", length = length(x))
  
  # Combining our variables in data frame
  mydata <- cbind.data.frame(x, y)
  
  # Fitting each point
  for(x0 in x) {
    
    # Setting population of window
    sample <- subset(mydata, between(x, x0-width/2, x0+width/2))
    n <- length(sample[,1])
    
    # Getting weights into diagonal matrix
    weights <- (1-(abs(sample[,1] - x0)/width*2)^3)^3
    W_mat <- diag(weights, n, n)
    
    # Checking degree and completing our regression accordingly
    if (degree == 1) {
      
      X_mat <- cbind(rep(1, n), sample[,1])
      betahat <- solve( t(X_mat)%*%W_mat%*%X_mat ) %*% t(X_mat) %*% W_mat %*% sample[,2]
      
      # Getting fitted value
      yhat[which(x0 == x)] <-  betahat[1] + betahat[2]*x0
    }
    else if (degree == 2) {
      
      X_mat <- cbind(rep(1, n), sample[,1], sample[,1]^2)
      betahat <- solve( t(X_mat)%*%W_mat%*%X_mat ) %*% t(X_mat) %*% W_mat %*% sample[,2]
      
      # Getting fitted value
      yhat[which(x0 == x)] <-  betahat[1] + betahat[2]*x0 + betahat[3]*x0^2
    }
    else {
      stop("Degree must be set to either 1 or 2")
    }
    
    # Getting population of window
    n_points[which(x0 == x)] <- n
  }
  
  # Calculating SSE, MSE, and residual standard error
  SSE <- sum((y-yhat)^{2})
  MSE <- SSE/(N_total-2)
  RSE <- sqrt(MSE)
  
  # Creating plot of final fit
  loessplot <- ggplot(mydata, aes(x, y)) +
    geom_point(size = 3, alpha = 0.5, color = "grey") +
    geom_line(aes(x, yhat), color = "red", lty = 1) +
    xlab(deparse(substitute(x))) + ylab(deparse(substitute(y))) +
    ggtitle(paste("LOESS with degree =", degree,"and span =", span, sep = " "))
  
  # Checking whether to show plot or not
  if (show.plot == T) {
    print(loessplot)
  }
  
  # Returning named list
  return(invisible(list(span = span, degree = degree, N_total = N_total, Win_total = Win_total,
              n_points = n_points, SSE = SSE, RSE = RSE, loessplot = loessplot)))
}
```




Determining LOESS regression fits on the data

```{r}
# Creating an empty data frame
fit_table <- data.frame()

# Determining fits and putting info into data frame
for(j in 1:2) {
  for (i in seq(0.25, 0.75, by = 0.05)) {
    fit_table <- rbind(fit_table, c(i, j, myloess(ozone$temperature, ozone$ozone,
                                                  span = i, degree = j, show.plot = F)$RSE))
  }
}

# Changing column names
colnames(fit_table) <- c("Span", "Degree", "RSE")

# Displaying data frame
fit_table
```


The three "best" fits with degree 1 appear to be span 0.25, 0.30, and 0.40. The three "best" fits with degree 2 appear to be span 0.25, 0.30, and 0.35.




Plotting the best fits found above

```{r}
myloess(ozone$temperature, ozone$ozone,
                                                  span = 0.25, degree = 1, show.plot = F)$loessplot
myloess(ozone$temperature, ozone$ozone,
                                                  span = 0.30, degree = 1, show.plot = F)$loessplot
myloess(ozone$temperature, ozone$ozone,
                                                  span = 0.40, degree = 1, show.plot = F)$loessplot
myloess(ozone$temperature, ozone$ozone,
                                                  span = 0.25, degree = 2, show.plot = F)$loessplot
myloess(ozone$temperature, ozone$ozone,
                                                  span = 0.30, degree = 2, show.plot = F)$loessplot
myloess(ozone$temperature, ozone$ozone,
                                                  span = 0.35, degree = 2, show.plot = F)$loessplot
```


Visually inspecting the best fits compared to the 2nd and 3rd best fits, we do feel we may have over-fit the data, especially for the fits with degree 2. The model with degree 1 and span 0.4 appears to be the "best" fit.


## Part c

Comparing results with built-in LOESS function

```{r}
ozone %>% ggplot(aes(temperature, ozone)) +
  geom_point() +
  geom_smooth(method = "loess", degree = 1, span = 0.40, se = F, method.args = list(degree=1))
```


The built-in LOESS function results in a fit that does not over-fit the data, but we feel our model provides the better fit.


# Problem 2

```{r}
library(MASS)
data("mcycle")

ggplot(mcycle, aes(x = times, y = accel)) + theme_bw() + geom_point()
```


## Part a

Determining LOESS regression fits on the data

```{r}
# Creating an empty data frame
fit_table2 <- data.frame()

# Determining fits and putting info into data frame
for(j in 1:2) {
  for (i in seq(0.25, 0.75, by = 0.05)) {
    fit_table2 <- rbind(fit_table2, c(i, j, myloess(mcycle$times, mcycle$accel,
                                                  span = i, degree = j, show.plot = F)$RSE))
  }
}

# Changing column names
colnames(fit_table2) <- c("Span", "Degree", "RSE")

# Displaying data frame
fit_table2
```


The three "best" fits with degree 1 appear to be span 0.25, 0.30, and 0.35. The three "best" fits with degree 2 appear to be span 0.25, 0.30, and 0.35.




Plotting the best fits found above

```{r}
myloess(mcycle$times, mcycle$accel,
                                                  span = 0.25, degree = 1, show.plot = F)$loessplot
myloess(mcycle$times, mcycle$accel,
                                                  span = 0.30, degree = 1, show.plot = F)$loessplot
myloess(mcycle$times, mcycle$accel,
                                                  span = 0.35, degree = 1, show.plot = F)$loessplot
myloess(mcycle$times, mcycle$accel,
                                                  span = 0.25, degree = 2, show.plot = F)$loessplot
myloess(mcycle$times, mcycle$accel,
                                                  span = 0.30, degree = 2, show.plot = F)$loessplot
myloess(mcycle$times, mcycle$accel,
                                                  span = 0.35, degree = 2, show.plot = F)$loessplot
```


Visually inspecting the models, we believe that the model with degree 2 and span 0.35 provided the "best" fit.


## Part b

Comparing results with built-in LOESS function

```{r}
mcycle %>% ggplot(aes(times, accel)) +
  geom_point() +
  geom_smooth(method = "loess", degree = 2, span = 0.35, se = F, method.args = list(degree=1))
```


The built-in LOESS function results in a fit that does not over-fit the data, but we feel our model provides the better fit.


# Problem 3

```{r}
# Some pre-processing
library(ISLR)
# Remove the name of the car model and change the origin to categorical with actual name
Auto_new <- Auto[, -9]
# Lookup table
newOrigin <- c("USA", "European", "Japanese")
Auto_new$origin <- factor(newOrigin[Auto_new$origin], newOrigin)

# Look at the first 6 observations to see the final version
head(Auto_new)
```


```{r}
library(caret)

# This function has the following inputs
#
# * train - matrix or data frame of training set cases
# * test - matrix or data frame of test set cases.  
#     (A vector will be interpreted as a row vector for a single case.)
# * y_train - Either a numeric vector, or factor vector for the responses in the training set
# * y_test - Either a numeric vector, or factor vector for the responses in the testing set
# * k - number of neighbors considered, the default value is 3
#
# If weighted = TRUE, then function uses the distance weighted kNN,
#  otherwise it does the default kNN method.

mykNN <- function(train, test, y_train, y_test, k = 3, weighted = TRUE) {
  
  # Allocating space for vector of fitted values
  yhat <- vector(mode = "numeric", length = length(y_test))
  
  # Fitting each point
  for (row in 1:nrow(test)) {
    
    # Getting features
    x0 <- test[row,]
    
    # Getting Euclidean distance and weights
    distmat <- as.matrix(dist(rbind(x0, train), method = "euclidean", diag = T, upper = T))
    dist <- distmat[1,]
    weights <- 1/dist
    
    # Getting kth nearest neighbor
    a.order <- order(weights, decreasing = T)[-1]
    last <- weights[a.order[k]]
    
    # Setting weights to 0 except for kNN
    y_train_sub <- y_train[-which(!is.finite(weights))]
    weights <- weights[-which(!is.finite(weights))]
    weights[weights < last] <- 0
    
    # Handling unweighted case
    if(weighted == F) {
      weights[weights != 0] <- 1
    }
    
    tot_weight <- sum(weights)
    
    # Handling classification
    if (is.factor(y_train)) {
      
      # Allocating space for vector of class weights
      class <- vector(mode = "numeric", length = nlevels(y_test))
      
      # Summing weights for each class
      for (i in 1:nlevels(y_test)) {
        class[i] <- sum(weights[which(y_train == levels(y_test)[i])])
      }
      
      # Assigning factor with highest class weight to yhat
      yhat[row] <- levels(y_test)[which(class == max(class))]
    }
    
    # Handling regression
    else {
      
      # Calculating yhat
      yhat[row] <- sum(weights*y_train/tot_weight)
    }
  }

  # Handling classification
  if (is.factor(y_train)) {
    
    yhat <- factor(yhat)
    
    # Setting number of correct predictions to 0
    num_correct <- 0
  
    # Getting number of correct predictions
    for (j in 1:length(yhat)) {
      
      # Checking if classes match
      if (y_test[j] == yhat[j]) {
        
        num_correct <- num_correct + 1
      }
    }
    
    # Calculating accuracy and error rate
    accuracy <- num_correct / length(yhat)
    error_rate <- 1 - accuracy
  
    # Getting confusion matrix
    confmat <- confusionMatrix(yhat, y_test)
    
    # Returning named list
    return(invisible(list(yhat = yhat, accuracy = accuracy,
                          error_rate = error_rate, confmat = confmat, k = k)))
  }
  
  # Handling regression
  else {
    
    # Calculating residuals, SSE, MSE, and residual standard error
    residuals <- y_test - yhat
    SSE <- sum(residuals^{2})
    MSE <- SSE/(nrow(test)-2)
    RSE <- sqrt(MSE)
    
    # Returning named list
    return(invisible(list(yhat = yhat, residuals = residuals, SSE = SSE, k = k)))
  }
}
```



```{r}
ntrain <- round(nrow(Auto_new)*0.7)
ntest <- nrow(Auto_new) - ntrain
train <- Auto_new[1:ntrain,1:7]
test <- Auto_new[(ntrain+1):nrow(Auto_new),1:7]
y_train <- Auto_new[1:ntrain,8]
y_test <- Auto_new[(ntrain+1):nrow(Auto_new),8]

trial2 <- mykNN(train, test, y_train, y_test, k = 3)
trial2
trial2$residuals
#ncol(train)

y_test
trial2$SSE


library(class)


#real <- knn(train, test, y_train, k = 3)
```


```{r}
"ozone4 <- as.data.frame(lapply(ozone[,3], nor))
ozone4 <- cbind(ozone4, ozone$ozone)
index <- sample(1:nrow(ozone4), round(nrow(ozone4) * 0.7))
training_df <- ozone4[index, ]
testing_df <- ozone4[-index, ]
train <- training_df[, 1]
test <- testing_df[, 1]
y_train <- training_df[,2]
y_test <- testing_df[,2]

trial2 <- mykNN2(train, test, y_train, y_test, k = 3)
trial2$residuals"
```



